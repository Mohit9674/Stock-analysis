{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mohitnotani/Desktop/Thesis/venv311/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Jupyter Notebook Cell\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "\n",
    "# 1. Load the news data\n",
    "news_df = pd.read_csv(\n",
    "    \"../data/processed/news_data_polygon.csv\",    \n",
    "    parse_dates=[\"ds\"]        \n",
    ")\n",
    "\n",
    "news_df = news_df.rename(columns={\"ds\": \"Date\", \"ticker\": \"Ticker\", \"headline\": \"Text\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "/Users/mohitnotani/Desktop/Thesis/venv311/lib/python3.11/site-packages/transformers/pipelines/text_classification.py:111: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n",
      "/Users/mohitnotani/Desktop/Thesis/venv311/lib/python3.11/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
    "model     = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\")\n",
    "sent_pipe = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model= model,\n",
    "    tokenizer= tokenizer,\n",
    "    return_all_scores=True\n",
    ")\n",
    "\n",
    "# 3. Define a helper to extract scores\n",
    "def extract_scores(text):\n",
    "    scores_list = sent_pipe(text)[0]   # list of dicts: [{\"label\":\"POS\",\"score\":...}, â€¦]\n",
    "    # map labels to lowercase keys\n",
    "    return {d[\"label\"].lower(): d[\"score\"] for d in scores_list}\n",
    "\n",
    "# 4. Run sentiment analysis (this may take a while if you have many rows)\n",
    "sentiments = news_df[\"Text\"].apply(extract_scores).apply(pd.Series)\n",
    "news_df = pd.concat([news_df, sentiments], axis=1)\n",
    "\n",
    "# 5. Aggregate to get a daily, per-ticker sentiment summary\n",
    "daily_sent = (\n",
    "    news_df\n",
    "    .groupby([\"Date\",\"Ticker\"])[[\"positive\",\"neutral\",\"negative\"]]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Date Ticker  positive   neutral  negative\n",
      "0    2023-06-01 00:00:00+00:00   AAPL  0.232926  0.643317  0.123757\n",
      "1    2023-06-01 00:00:00+00:00  GOOGL  0.319815  0.497703  0.182482\n",
      "2    2023-06-01 00:00:00+00:00   TSLA  0.292940  0.520992  0.186068\n",
      "3    2023-06-02 00:00:00+00:00   AAPL  0.171210  0.651650  0.177140\n",
      "4    2023-06-02 00:00:00+00:00  GOOGL  0.166422  0.706851  0.126727\n",
      "...                        ...    ...       ...       ...       ...\n",
      "2137 2025-05-31 00:00:00+00:00  GOOGL  0.057143  0.723633  0.219224\n",
      "2138 2025-05-31 00:00:00+00:00   TSLA  0.086500  0.876373  0.037127\n",
      "2139 2025-06-01 00:00:00+00:00   AAPL  0.048652  0.867846  0.083501\n",
      "2140 2025-06-01 00:00:00+00:00  GOOGL  0.210159  0.747900  0.041942\n",
      "2141 2025-06-01 00:00:00+00:00   TSLA  0.122550  0.854050  0.023399\n",
      "\n",
      "[2142 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(daily_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date        Open        High         Low       Close       Volume  \\\n",
      "0 2022-09-13  157.593780  158.224549  151.157963  151.621185  122656600.0   \n",
      "1 2022-09-14  152.557473  154.834168  151.394499  153.069977   87965400.0   \n",
      "2 2022-09-15  152.419493  153.000995  149.196667  150.172379   90481100.0   \n",
      "3 2022-09-16  149.029113  149.167093  146.230062  148.526459  162278800.0   \n",
      "4 2022-09-19  147.156536  152.330816  146.949573  152.251968   81474200.0   \n",
      "\n",
      "  Ticker       Ret       SMA20       SMA50  ...  MACD_diff      RSI14  \\\n",
      "0   AAPL -0.058680  160.654005  156.484178  ...  -1.110677  41.021561   \n",
      "1   AAPL  0.009555  159.780782  156.810853  ...  -1.027681  43.356484   \n",
      "2   AAPL -0.018930  158.687776  157.001034  ...  -1.101642  39.949951   \n",
      "3   AAPL -0.010960  157.532187  157.090781  ...  -1.187715  38.117879   \n",
      "4   AAPL  0.025083  156.692474  157.241455  ...  -0.931367  44.339906   \n",
      "\n",
      "       BB_mid     BB_high      BB_low    BB_pct   BB_width  positive  neutral  \\\n",
      "0  160.654005  174.451377  146.856632  0.172662  17.176506       NaN      NaN   \n",
      "1  159.780782  173.170939  146.390624  0.249413  16.760661       NaN      NaN   \n",
      "2  158.687776  171.453398  145.922154  0.166471  16.088979       NaN      NaN   \n",
      "3  157.532187  169.562445  145.501929  0.125705  15.273396       NaN      NaN   \n",
      "4  156.692474  167.691028  145.693920  0.298132  14.038395       NaN      NaN   \n",
      "\n",
      "   negative  \n",
      "0       NaN  \n",
      "1       NaN  \n",
      "2       NaN  \n",
      "3       NaN  \n",
      "4       NaN  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "# 6. Load your features (stationary) dataframe\n",
    "feat_df = pd.read_csv(\n",
    "    \"../data/processed/features_stationary.csv\",  # adjust path if needed\n",
    "    parse_dates=[\"Date\"]\n",
    ")\n",
    "\n",
    "feat_df[\"Date\"] = pd.to_datetime(feat_df[\"Date\"])\\\n",
    "                     .dt.tz_localize(None)\n",
    "\n",
    "# 2) same for daily_sent[\"Date\"]\n",
    "daily_sent[\"Date\"] = pd.to_datetime(daily_sent[\"Date\"])\\\n",
    "                         .dt.tz_localize(None)\n",
    "\n",
    "\n",
    "# 7. Merge the sentiment scores into your features\n",
    "merged_df = feat_df.merge(\n",
    "    daily_sent,\n",
    "    on=[\"Date\",\"Ticker\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# 9. Quick check\n",
    "print(merged_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jq/mbgbv6211m9816f1py7zsb0c0000gn/T/ipykernel_98155/3207139805.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df[col].fillna(0.0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "merged_df[\"has_sentiment\"] = merged_df[\"positive\"].notna().astype(int)\n",
    "\n",
    "# neutral imputation\n",
    "for col in [\"positive\",\"neutral\",\"negative\"]:\n",
    "    merged_df[col].fillna(0.0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Save the new dataframe\n",
    "merged_df.to_csv(\n",
    "    \"../data/processed/features_with_sentiment.csv\",\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
